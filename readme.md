# ğŸŒ Machine Translation EN â†’ VI  
**Fine-tuning a Transformer model for English â†’ Vietnamese translation**

---

## ğŸ“˜ 1. Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y huáº¥n luyá»‡n mÃ´ hÃ¬nh **dá»‹ch mÃ¡y (Machine Translation)** tá»« tiáº¿ng **Anh â†’ Viá»‡t**  
dá»±a trÃªn kiáº¿n trÃºc **Transformer (MarianMT)** sá»­ dá»¥ng thÆ° viá»‡n **Hugging Face Transformers**.

### ğŸ¯ Má»¥c tiÃªu
- TÃ¬m hiá»ƒu quy trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh Seq2Seq (Sequence-to-Sequence)
- Ãp dá»¥ng fine-tuning mÃ´ hÃ¬nh `Helsinki-NLP/opus-mt-en-vi`
- Táº¡o API/inference Ä‘á»ƒ dá»‹ch vÄƒn báº£n tiáº¿ng Anh sang tiáº¿ng Viá»‡t

---

## ğŸ§  2. Kiáº¿n thá»©c ná»n táº£ng

### ğŸ”¹ Cáº¥u trÃºc Transformer
- **Encoder**: mÃ£ hÃ³a cÃ¢u tiáº¿ng Anh thÃ nh vector ngá»¯ nghÄ©a
- **Decoder**: giáº£i mÃ£ vector ngá»¯ nghÄ©a thÃ nh cÃ¢u tiáº¿ng Viá»‡t
- CÆ¡ cháº¿ **Attention** giÃºp mÃ´ hÃ¬nh â€œtáº­p trungâ€ vÃ o cÃ¡c tá»« quan trá»ng trong ngá»¯ cáº£nh

### ğŸ”¹ Huáº¥n luyá»‡n Seq2Seq
- Input: CÃ¢u tiáº¿ng Anh (source)
- Target: CÃ¢u tiáº¿ng Viá»‡t (target)
- Loss function: Cross-Entropy giá»¯a cÃ¢u dá»± Ä‘oÃ¡n vÃ  cÃ¢u tháº­t
- Optimizer: AdamW, Learning Rate Scheduler, Warmup Steps

---

## ğŸ§© 3. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

### YÃªu cáº§u há»‡ thá»‘ng
- Python â‰¥ 3.9  
- GPU cÃ³ CUDA (khuyáº¿n nghá»‹)
- pip hoáº·c conda environment

### BÆ°á»›c cÃ i Ä‘áº·t

```bash
# Clone project
git clone https://github.com/<your-username>/MachineTranslation.git
cd MachineTranslation

# Táº¡o virtual environment
python -m venv .venv
source .venv/Scripts/activate    # Windows: .venv\Scripts\activate

# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt

